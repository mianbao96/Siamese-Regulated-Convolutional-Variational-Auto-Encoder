{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as datasets\n",
    "#from vae import VAE\n",
    "from vaecnn import VAECNN\n",
    "#from util import train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    #BCE = F.binary_cross_entropy(recon_x, x, reduction='sum') #.view(-1, 784)\n",
    "    BCE = F.mse_loss(recon_x, x, size_average=True)\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = (-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))/64\n",
    "    \n",
    "    print('BCE',BCE)\n",
    "    print('KLD',KLD)\n",
    "    \n",
    "    return  BCE + 0.01 * (KLD )\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        #print(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar,_ = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar, _ = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "#             if i == 0:\n",
    "#                 n = min(data.size(0), 8)\n",
    "#                 comparison = torch.cat([data[:n],\n",
    "#                                       recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "#                 save_image(comparison.cpu(),\n",
    "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    batch_size = 150,\n",
    "    epochs = 10,\n",
    "    cuda = True,\n",
    "    seed = 2019,\n",
    "    log_interval = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "trainDataDir = '/scratch/um367/DL/data/sample_4/train'\n",
    "valDataDir = '/scratch/um367/DL/data/sample_4/val'\n",
    "# trainDataDir = '/scratch/um367/DL/data/sampledata/supervised/train'\n",
    "# valDataDir = '/scratch/um367/DL/data/sampledata/supervised/val'\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(trainDataDir, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valDataDir, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAECNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load parameters\n",
    "# to load\n",
    "checkpoint = torch.load('vaetest2.pth.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0860, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [0/128000 (0%)]\tLoss: 0.000574\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [150/128000 (0%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [300/128000 (0%)]\tLoss: 0.000585\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [450/128000 (0%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [600/128000 (0%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [750/128000 (1%)]\tLoss: 0.000568\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [900/128000 (1%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0871, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1050/128000 (1%)]\tLoss: 0.000590\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1200/128000 (1%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1350/128000 (1%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1500/128000 (1%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1650/128000 (1%)]\tLoss: 0.000557\n",
      "BCE tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1800/128000 (1%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0880, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1950/128000 (2%)]\tLoss: 0.000587\n",
      "BCE tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2100/128000 (2%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2250/128000 (2%)]\tLoss: 0.000556\n",
      "BCE tensor(0.0848, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2400/128000 (2%)]\tLoss: 0.000568\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2550/128000 (2%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2700/128000 (2%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2850/128000 (2%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0707, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3000/128000 (2%)]\tLoss: 0.000473\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3150/128000 (2%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3300/128000 (3%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3450/128000 (3%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3600/128000 (3%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3750/128000 (3%)]\tLoss: 0.000587\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3900/128000 (3%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4050/128000 (3%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4200/128000 (3%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4350/128000 (3%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4500/128000 (4%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4650/128000 (4%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4800/128000 (4%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4950/128000 (4%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5100/128000 (4%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5250/128000 (4%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5400/128000 (4%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5550/128000 (4%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5700/128000 (4%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5850/128000 (5%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6000/128000 (5%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6150/128000 (5%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6300/128000 (5%)]\tLoss: 0.000486\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6450/128000 (5%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6600/128000 (5%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0888, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6750/128000 (5%)]\tLoss: 0.000592\n",
      "BCE tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6900/128000 (5%)]\tLoss: 0.000499\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7050/128000 (6%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7200/128000 (6%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7350/128000 (6%)]\tLoss: 0.000492\n",
      "BCE tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7500/128000 (6%)]\tLoss: 0.000577\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7650/128000 (6%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7800/128000 (6%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7950/128000 (6%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8100/128000 (6%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8250/128000 (6%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8400/128000 (7%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8550/128000 (7%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8700/128000 (7%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8850/128000 (7%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9000/128000 (7%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9150/128000 (7%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9300/128000 (7%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9450/128000 (7%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9600/128000 (7%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9750/128000 (8%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9900/128000 (8%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10050/128000 (8%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10200/128000 (8%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10350/128000 (8%)]\tLoss: 0.000494\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10500/128000 (8%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10650/128000 (8%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10800/128000 (8%)]\tLoss: 0.000584\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10950/128000 (9%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11100/128000 (9%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11250/128000 (9%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11400/128000 (9%)]\tLoss: 0.000515\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11550/128000 (9%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11700/128000 (9%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11850/128000 (9%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12000/128000 (9%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12150/128000 (9%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0848, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12300/128000 (10%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12450/128000 (10%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12600/128000 (10%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12750/128000 (10%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12900/128000 (10%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13050/128000 (10%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0838, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13200/128000 (10%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13350/128000 (10%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13500/128000 (11%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13650/128000 (11%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13800/128000 (11%)]\tLoss: 0.000581\n",
      "BCE tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13950/128000 (11%)]\tLoss: 0.000491\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [14100/128000 (11%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14250/128000 (11%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [14400/128000 (11%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0895, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [14550/128000 (11%)]\tLoss: 0.000597\n",
      "BCE tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [14700/128000 (11%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [14850/128000 (12%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15000/128000 (12%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15150/128000 (12%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15300/128000 (12%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15450/128000 (12%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15600/128000 (12%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15750/128000 (12%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15900/128000 (12%)]\tLoss: 0.000590\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16050/128000 (13%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16200/128000 (13%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16350/128000 (13%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16500/128000 (13%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16650/128000 (13%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16800/128000 (13%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16950/128000 (13%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17100/128000 (13%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17250/128000 (13%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17400/128000 (14%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17550/128000 (14%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17700/128000 (14%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17850/128000 (14%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18000/128000 (14%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18150/128000 (14%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18300/128000 (14%)]\tLoss: 0.000513\n",
      "BCE tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18450/128000 (14%)]\tLoss: 0.000469\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18600/128000 (15%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18750/128000 (15%)]\tLoss: 0.000559\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18900/128000 (15%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19050/128000 (15%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19200/128000 (15%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19350/128000 (15%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19500/128000 (15%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19650/128000 (15%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19800/128000 (15%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19950/128000 (16%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20100/128000 (16%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0899, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20250/128000 (16%)]\tLoss: 0.000600\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20400/128000 (16%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20550/128000 (16%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20700/128000 (16%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20850/128000 (16%)]\tLoss: 0.000593\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21000/128000 (16%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21150/128000 (17%)]\tLoss: 0.000552\n",
      "BCE tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21300/128000 (17%)]\tLoss: 0.000504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0860, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21450/128000 (17%)]\tLoss: 0.000574\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21600/128000 (17%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0838, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21750/128000 (17%)]\tLoss: 0.000559\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21900/128000 (17%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22050/128000 (17%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22200/128000 (17%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22350/128000 (17%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22500/128000 (18%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22650/128000 (18%)]\tLoss: 0.000569\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22800/128000 (18%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22950/128000 (18%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23100/128000 (18%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0739, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23250/128000 (18%)]\tLoss: 0.000493\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23400/128000 (18%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23550/128000 (18%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23700/128000 (19%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23850/128000 (19%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24000/128000 (19%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24150/128000 (19%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24300/128000 (19%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24450/128000 (19%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24600/128000 (19%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24750/128000 (19%)]\tLoss: 0.000556\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24900/128000 (19%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25050/128000 (20%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25200/128000 (20%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0870, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25350/128000 (20%)]\tLoss: 0.000580\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25500/128000 (20%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25650/128000 (20%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0871, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25800/128000 (20%)]\tLoss: 0.000581\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25950/128000 (20%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0747, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26100/128000 (20%)]\tLoss: 0.000498\n",
      "BCE tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26250/128000 (20%)]\tLoss: 0.000556\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26400/128000 (21%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26550/128000 (21%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26700/128000 (21%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26850/128000 (21%)]\tLoss: 0.000582\n",
      "BCE tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27000/128000 (21%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0895, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27150/128000 (21%)]\tLoss: 0.000597\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27300/128000 (21%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27450/128000 (21%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27600/128000 (22%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27750/128000 (22%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27900/128000 (22%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28050/128000 (22%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28200/128000 (22%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28350/128000 (22%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [28500/128000 (22%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28650/128000 (22%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28800/128000 (22%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28950/128000 (23%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29100/128000 (23%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29250/128000 (23%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29400/128000 (23%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29550/128000 (23%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29700/128000 (23%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29850/128000 (23%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30000/128000 (23%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30150/128000 (24%)]\tLoss: 0.000492\n",
      "BCE tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30300/128000 (24%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30450/128000 (24%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0902, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30600/128000 (24%)]\tLoss: 0.000602\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30750/128000 (24%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30900/128000 (24%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31050/128000 (24%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31200/128000 (24%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0727, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31350/128000 (24%)]\tLoss: 0.000485\n",
      "BCE tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31500/128000 (25%)]\tLoss: 0.000506\n",
      "BCE tensor(0.0879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31650/128000 (25%)]\tLoss: 0.000586\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31800/128000 (25%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31950/128000 (25%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [32100/128000 (25%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [32250/128000 (25%)]\tLoss: 0.000501\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [32400/128000 (25%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [32550/128000 (25%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [32700/128000 (26%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [32850/128000 (26%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33000/128000 (26%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33150/128000 (26%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33300/128000 (26%)]\tLoss: 0.000584\n",
      "BCE tensor(0.0745, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33450/128000 (26%)]\tLoss: 0.000497\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33600/128000 (26%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33750/128000 (26%)]\tLoss: 0.000572\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [33900/128000 (26%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34050/128000 (27%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34200/128000 (27%)]\tLoss: 0.000500\n",
      "BCE tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34350/128000 (27%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34500/128000 (27%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34650/128000 (27%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34800/128000 (27%)]\tLoss: 0.000573\n",
      "BCE tensor(0.0860, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [34950/128000 (27%)]\tLoss: 0.000573\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [35100/128000 (27%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [35250/128000 (28%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [35400/128000 (28%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [35550/128000 (28%)]\tLoss: 0.000519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [35700/128000 (28%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [35850/128000 (28%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36000/128000 (28%)]\tLoss: 0.000570\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36150/128000 (28%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36300/128000 (28%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0711, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36450/128000 (28%)]\tLoss: 0.000474\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36600/128000 (29%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36750/128000 (29%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [36900/128000 (29%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0857, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37050/128000 (29%)]\tLoss: 0.000572\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37200/128000 (29%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37350/128000 (29%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0764, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37500/128000 (29%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37650/128000 (29%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37800/128000 (30%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [37950/128000 (30%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [38100/128000 (30%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0735, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [38250/128000 (30%)]\tLoss: 0.000490\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [38400/128000 (30%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [38550/128000 (30%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [38700/128000 (30%)]\tLoss: 0.000575\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [38850/128000 (30%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39000/128000 (30%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39150/128000 (31%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39300/128000 (31%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39450/128000 (31%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39600/128000 (31%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39750/128000 (31%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [39900/128000 (31%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40050/128000 (31%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40200/128000 (31%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40350/128000 (31%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40500/128000 (32%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40650/128000 (32%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40800/128000 (32%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [40950/128000 (32%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [41100/128000 (32%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [41250/128000 (32%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [41400/128000 (32%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [41550/128000 (32%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [41700/128000 (33%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [41850/128000 (33%)]\tLoss: 0.000490\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [42000/128000 (33%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [42150/128000 (33%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [42300/128000 (33%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [42450/128000 (33%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [42600/128000 (33%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [42750/128000 (33%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [42900/128000 (33%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43050/128000 (34%)]\tLoss: 0.000503\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43200/128000 (34%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43350/128000 (34%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43500/128000 (34%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43650/128000 (34%)]\tLoss: 0.000491\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43800/128000 (34%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [43950/128000 (34%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [44100/128000 (34%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [44250/128000 (35%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [44400/128000 (35%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [44550/128000 (35%)]\tLoss: 0.000552\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [44700/128000 (35%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [44850/128000 (35%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45000/128000 (35%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45150/128000 (35%)]\tLoss: 0.000577\n",
      "BCE tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45300/128000 (35%)]\tLoss: 0.000585\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45450/128000 (35%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45600/128000 (36%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45750/128000 (36%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [45900/128000 (36%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46050/128000 (36%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46200/128000 (36%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46350/128000 (36%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46500/128000 (36%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46650/128000 (36%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46800/128000 (37%)]\tLoss: 0.000464\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [46950/128000 (37%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [47100/128000 (37%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [47250/128000 (37%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [47400/128000 (37%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [47550/128000 (37%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [47700/128000 (37%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [47850/128000 (37%)]\tLoss: 0.000494\n",
      "BCE tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48000/128000 (37%)]\tLoss: 0.000584\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48150/128000 (38%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48300/128000 (38%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48450/128000 (38%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48600/128000 (38%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48750/128000 (38%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [48900/128000 (38%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49050/128000 (38%)]\tLoss: 0.000596\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49200/128000 (38%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49350/128000 (39%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0871, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49500/128000 (39%)]\tLoss: 0.000581\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49650/128000 (39%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49800/128000 (39%)]\tLoss: 0.000523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [49950/128000 (39%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [50100/128000 (39%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [50250/128000 (39%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [50400/128000 (39%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [50550/128000 (39%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [50700/128000 (40%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [50850/128000 (40%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51000/128000 (40%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51150/128000 (40%)]\tLoss: 0.000479\n",
      "BCE tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51300/128000 (40%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51450/128000 (40%)]\tLoss: 0.000569\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51600/128000 (40%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51750/128000 (40%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [51900/128000 (41%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52050/128000 (41%)]\tLoss: 0.000529\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52200/128000 (41%)]\tLoss: 0.000513\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52350/128000 (41%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52500/128000 (41%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52650/128000 (41%)]\tLoss: 0.000585\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52800/128000 (41%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [52950/128000 (41%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [53100/128000 (41%)]\tLoss: 0.000495\n",
      "BCE tensor(0.0840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [53250/128000 (42%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0751, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [53400/128000 (42%)]\tLoss: 0.000501\n",
      "BCE tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [53550/128000 (42%)]\tLoss: 0.000559\n",
      "BCE tensor(0.0738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [53700/128000 (42%)]\tLoss: 0.000492\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [53850/128000 (42%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54000/128000 (42%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0870, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54150/128000 (42%)]\tLoss: 0.000580\n",
      "BCE tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54300/128000 (42%)]\tLoss: 0.000495\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54450/128000 (43%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0851, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54600/128000 (43%)]\tLoss: 0.000567\n",
      "BCE tensor(0.0835, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54750/128000 (43%)]\tLoss: 0.000557\n",
      "BCE tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [54900/128000 (43%)]\tLoss: 0.000491\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55050/128000 (43%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0861, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55200/128000 (43%)]\tLoss: 0.000574\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55350/128000 (43%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55500/128000 (43%)]\tLoss: 0.000491\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55650/128000 (43%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55800/128000 (44%)]\tLoss: 0.000567\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [55950/128000 (44%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [56100/128000 (44%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0751, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [56250/128000 (44%)]\tLoss: 0.000501\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [56400/128000 (44%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [56550/128000 (44%)]\tLoss: 0.000570\n",
      "BCE tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [56700/128000 (44%)]\tLoss: 0.000569\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [56850/128000 (44%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [57000/128000 (44%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [57150/128000 (45%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [57300/128000 (45%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [57450/128000 (45%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [57600/128000 (45%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0717, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [57750/128000 (45%)]\tLoss: 0.000478\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [57900/128000 (45%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58050/128000 (45%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58200/128000 (45%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0868, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58350/128000 (46%)]\tLoss: 0.000579\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58500/128000 (46%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58650/128000 (46%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58800/128000 (46%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0733, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [58950/128000 (46%)]\tLoss: 0.000489\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [59100/128000 (46%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [59250/128000 (46%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [59400/128000 (46%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [59550/128000 (46%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [59700/128000 (47%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [59850/128000 (47%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60000/128000 (47%)]\tLoss: 0.000494\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60150/128000 (47%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60300/128000 (47%)]\tLoss: 0.000575\n",
      "BCE tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60450/128000 (47%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60600/128000 (47%)]\tLoss: 0.000569\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60750/128000 (47%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [60900/128000 (48%)]\tLoss: 0.000575\n",
      "BCE tensor(0.0759, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61050/128000 (48%)]\tLoss: 0.000506\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61200/128000 (48%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61350/128000 (48%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0866, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61500/128000 (48%)]\tLoss: 0.000578\n",
      "BCE tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61650/128000 (48%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61800/128000 (48%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [61950/128000 (48%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [62100/128000 (48%)]\tLoss: 0.000572\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [62250/128000 (49%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0848, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [62400/128000 (49%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [62550/128000 (49%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [62700/128000 (49%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [62850/128000 (49%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63000/128000 (49%)]\tLoss: 0.000576\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63150/128000 (49%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0904, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63300/128000 (49%)]\tLoss: 0.000603\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63450/128000 (50%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63600/128000 (50%)]\tLoss: 0.000513\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63750/128000 (50%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [63900/128000 (50%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64050/128000 (50%)]\tLoss: 0.000526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64200/128000 (50%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64350/128000 (50%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64500/128000 (50%)]\tLoss: 0.000513\n",
      "BCE tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64650/128000 (50%)]\tLoss: 0.000575\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64800/128000 (51%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [64950/128000 (51%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [65100/128000 (51%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [65250/128000 (51%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [65400/128000 (51%)]\tLoss: 0.000556\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [65550/128000 (51%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [65700/128000 (51%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [65850/128000 (51%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66000/128000 (52%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66150/128000 (52%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66300/128000 (52%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66450/128000 (52%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66600/128000 (52%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66750/128000 (52%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [66900/128000 (52%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0851, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67050/128000 (52%)]\tLoss: 0.000567\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67200/128000 (52%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67350/128000 (53%)]\tLoss: 0.000577\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67500/128000 (53%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67650/128000 (53%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67800/128000 (53%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0764, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [67950/128000 (53%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [68100/128000 (53%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0897, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [68250/128000 (53%)]\tLoss: 0.000598\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [68400/128000 (53%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [68550/128000 (54%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [68700/128000 (54%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [68850/128000 (54%)]\tLoss: 0.000577\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69000/128000 (54%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69150/128000 (54%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69300/128000 (54%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69450/128000 (54%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69600/128000 (54%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69750/128000 (54%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [69900/128000 (55%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70050/128000 (55%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70200/128000 (55%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70350/128000 (55%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70500/128000 (55%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70650/128000 (55%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70800/128000 (55%)]\tLoss: 0.000587\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [70950/128000 (55%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [71100/128000 (56%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [71250/128000 (56%)]\tLoss: 0.000556\n",
      "BCE tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [71400/128000 (56%)]\tLoss: 0.000494\n",
      "BCE tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [71550/128000 (56%)]\tLoss: 0.000596\n",
      "BCE tensor(0.0738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [71700/128000 (56%)]\tLoss: 0.000492\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [71850/128000 (56%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72000/128000 (56%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72150/128000 (56%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72300/128000 (56%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72450/128000 (57%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72600/128000 (57%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72750/128000 (57%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [72900/128000 (57%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73050/128000 (57%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73200/128000 (57%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73350/128000 (57%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73500/128000 (57%)]\tLoss: 0.000497\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73650/128000 (57%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73800/128000 (58%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [73950/128000 (58%)]\tLoss: 0.000503\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [74100/128000 (58%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [74250/128000 (58%)]\tLoss: 0.000573\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [74400/128000 (58%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [74550/128000 (58%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [74700/128000 (58%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [74850/128000 (58%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75000/128000 (59%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75150/128000 (59%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75300/128000 (59%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75450/128000 (59%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75600/128000 (59%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75750/128000 (59%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [75900/128000 (59%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76050/128000 (59%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76200/128000 (59%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76350/128000 (60%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76500/128000 (60%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76650/128000 (60%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0857, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76800/128000 (60%)]\tLoss: 0.000572\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [76950/128000 (60%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [77100/128000 (60%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [77250/128000 (60%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [77400/128000 (60%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [77550/128000 (61%)]\tLoss: 0.000505\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [77700/128000 (61%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [77850/128000 (61%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78000/128000 (61%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78150/128000 (61%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78300/128000 (61%)]\tLoss: 0.000509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0759, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78450/128000 (61%)]\tLoss: 0.000506\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78600/128000 (61%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78750/128000 (61%)]\tLoss: 0.000551\n",
      "BCE tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [78900/128000 (62%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79050/128000 (62%)]\tLoss: 0.000497\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79200/128000 (62%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0883, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79350/128000 (62%)]\tLoss: 0.000589\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79500/128000 (62%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79650/128000 (62%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79800/128000 (62%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [79950/128000 (62%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [80100/128000 (63%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [80250/128000 (63%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [80400/128000 (63%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [80550/128000 (63%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [80700/128000 (63%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0835, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [80850/128000 (63%)]\tLoss: 0.000557\n",
      "BCE tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81000/128000 (63%)]\tLoss: 0.000596\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81150/128000 (63%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81300/128000 (63%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81450/128000 (64%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81600/128000 (64%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81750/128000 (64%)]\tLoss: 0.000504\n",
      "BCE tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [81900/128000 (64%)]\tLoss: 0.000569\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82050/128000 (64%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82200/128000 (64%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82350/128000 (64%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82500/128000 (64%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82650/128000 (65%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82800/128000 (65%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [82950/128000 (65%)]\tLoss: 0.000593\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [83100/128000 (65%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [83250/128000 (65%)]\tLoss: 0.000504\n",
      "BCE tensor(0.0838, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [83400/128000 (65%)]\tLoss: 0.000559\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [83550/128000 (65%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [83700/128000 (65%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [83850/128000 (65%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84000/128000 (66%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84150/128000 (66%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84300/128000 (66%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84450/128000 (66%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84600/128000 (66%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84750/128000 (66%)]\tLoss: 0.000500\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [84900/128000 (66%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [85050/128000 (66%)]\tLoss: 0.000508\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [85200/128000 (67%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [85350/128000 (67%)]\tLoss: 0.000582\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [85500/128000 (67%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [85650/128000 (67%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [85800/128000 (67%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [85950/128000 (67%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [86100/128000 (67%)]\tLoss: 0.000576\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [86250/128000 (67%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [86400/128000 (67%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [86550/128000 (68%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [86700/128000 (68%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [86850/128000 (68%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87000/128000 (68%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87150/128000 (68%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87300/128000 (68%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87450/128000 (68%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87600/128000 (68%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87750/128000 (69%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [87900/128000 (69%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88050/128000 (69%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88200/128000 (69%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88350/128000 (69%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88500/128000 (69%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88650/128000 (69%)]\tLoss: 0.000515\n",
      "BCE tensor(0.0864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88800/128000 (69%)]\tLoss: 0.000576\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [88950/128000 (69%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [89100/128000 (70%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [89250/128000 (70%)]\tLoss: 0.000556\n",
      "BCE tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [89400/128000 (70%)]\tLoss: 0.000500\n",
      "BCE tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [89550/128000 (70%)]\tLoss: 0.000491\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [89700/128000 (70%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [89850/128000 (70%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90000/128000 (70%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90150/128000 (70%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90300/128000 (70%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90450/128000 (71%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90600/128000 (71%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90750/128000 (71%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [90900/128000 (71%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91050/128000 (71%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91200/128000 (71%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91350/128000 (71%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91500/128000 (71%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91650/128000 (72%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91800/128000 (72%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [91950/128000 (72%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [92100/128000 (72%)]\tLoss: 0.000570\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [92250/128000 (72%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [92400/128000 (72%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0878, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [92550/128000 (72%)]\tLoss: 0.000586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [92700/128000 (72%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [92850/128000 (72%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93000/128000 (73%)]\tLoss: 0.000491\n",
      "BCE tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93150/128000 (73%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93300/128000 (73%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93450/128000 (73%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93600/128000 (73%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93750/128000 (73%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [93900/128000 (73%)]\tLoss: 0.000500\n",
      "BCE tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94050/128000 (73%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94200/128000 (74%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94350/128000 (74%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0707, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94500/128000 (74%)]\tLoss: 0.000472\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94650/128000 (74%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94800/128000 (74%)]\tLoss: 0.000575\n",
      "BCE tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [94950/128000 (74%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [95100/128000 (74%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [95250/128000 (74%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [95400/128000 (74%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [95550/128000 (75%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [95700/128000 (75%)]\tLoss: 0.000572\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [95850/128000 (75%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96000/128000 (75%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96150/128000 (75%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96300/128000 (75%)]\tLoss: 0.000591\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96450/128000 (75%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96600/128000 (75%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0860, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96750/128000 (76%)]\tLoss: 0.000574\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [96900/128000 (76%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97050/128000 (76%)]\tLoss: 0.000515\n",
      "BCE tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97200/128000 (76%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0869, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97350/128000 (76%)]\tLoss: 0.000580\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97500/128000 (76%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97650/128000 (76%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97800/128000 (76%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0751, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [97950/128000 (76%)]\tLoss: 0.000501\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [98100/128000 (77%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [98250/128000 (77%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [98400/128000 (77%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [98550/128000 (77%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [98700/128000 (77%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0856, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [98850/128000 (77%)]\tLoss: 0.000571\n",
      "BCE tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [99000/128000 (77%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [99150/128000 (77%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [99300/128000 (78%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0878, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [99450/128000 (78%)]\tLoss: 0.000586\n",
      "BCE tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [99600/128000 (78%)]\tLoss: 0.000557\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [99750/128000 (78%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [99900/128000 (78%)]\tLoss: 0.000515\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100050/128000 (78%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100200/128000 (78%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100350/128000 (78%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100500/128000 (78%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100650/128000 (79%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100800/128000 (79%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [100950/128000 (79%)]\tLoss: 0.000505\n",
      "BCE tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [101100/128000 (79%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [101250/128000 (79%)]\tLoss: 0.000485\n",
      "BCE tensor(0.0840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [101400/128000 (79%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [101550/128000 (79%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [101700/128000 (79%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [101850/128000 (80%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102000/128000 (80%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102150/128000 (80%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102300/128000 (80%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102450/128000 (80%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102600/128000 (80%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102750/128000 (80%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [102900/128000 (80%)]\tLoss: 0.000509\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103050/128000 (80%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103200/128000 (81%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103350/128000 (81%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103500/128000 (81%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103650/128000 (81%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103800/128000 (81%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [103950/128000 (81%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [104100/128000 (81%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0723, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [104250/128000 (81%)]\tLoss: 0.000482\n",
      "BCE tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [104400/128000 (81%)]\tLoss: 0.000498\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [104550/128000 (82%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [104700/128000 (82%)]\tLoss: 0.000519\n",
      "BCE tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [104850/128000 (82%)]\tLoss: 0.000523\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105000/128000 (82%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105150/128000 (82%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105300/128000 (82%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105450/128000 (82%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105600/128000 (82%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105750/128000 (83%)]\tLoss: 0.000577\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [105900/128000 (83%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [106050/128000 (83%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [106200/128000 (83%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [106350/128000 (83%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [106500/128000 (83%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [106650/128000 (83%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [106800/128000 (83%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [106950/128000 (83%)]\tLoss: 0.000585\n",
      "BCE tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [107100/128000 (84%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [107250/128000 (84%)]\tLoss: 0.000552\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [107400/128000 (84%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [107550/128000 (84%)]\tLoss: 0.000538\n",
      "BCE tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [107700/128000 (84%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [107850/128000 (84%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108000/128000 (84%)]\tLoss: 0.000573\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108150/128000 (84%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108300/128000 (85%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108450/128000 (85%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108600/128000 (85%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108750/128000 (85%)]\tLoss: 0.000555\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [108900/128000 (85%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109050/128000 (85%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109200/128000 (85%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109350/128000 (85%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109500/128000 (85%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109650/128000 (86%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109800/128000 (86%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [109950/128000 (86%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [110100/128000 (86%)]\tLoss: 0.000520\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [110250/128000 (86%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [110400/128000 (86%)]\tLoss: 0.000529\n",
      "BCE tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [110550/128000 (86%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [110700/128000 (86%)]\tLoss: 0.000570\n",
      "BCE tensor(0.0708, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [110850/128000 (87%)]\tLoss: 0.000473\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111000/128000 (87%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111150/128000 (87%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111300/128000 (87%)]\tLoss: 0.000513\n",
      "BCE tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111450/128000 (87%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111600/128000 (87%)]\tLoss: 0.000568\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111750/128000 (87%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [111900/128000 (87%)]\tLoss: 0.000552\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112050/128000 (87%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112200/128000 (88%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112350/128000 (88%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112500/128000 (88%)]\tLoss: 0.000503\n",
      "BCE tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112650/128000 (88%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112800/128000 (88%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [112950/128000 (88%)]\tLoss: 0.000530\n",
      "BCE tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [113100/128000 (88%)]\tLoss: 0.000493\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [113250/128000 (88%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [113400/128000 (89%)]\tLoss: 0.000566\n",
      "BCE tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [113550/128000 (89%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [113700/128000 (89%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [113850/128000 (89%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114000/128000 (89%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114150/128000 (89%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114300/128000 (89%)]\tLoss: 0.000554\n",
      "BCE tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114450/128000 (89%)]\tLoss: 0.000580\n",
      "BCE tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114600/128000 (89%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114750/128000 (90%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [114900/128000 (90%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115050/128000 (90%)]\tLoss: 0.000511\n",
      "BCE tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115200/128000 (90%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115350/128000 (90%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115500/128000 (90%)]\tLoss: 0.000533\n",
      "BCE tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115650/128000 (90%)]\tLoss: 0.000553\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115800/128000 (90%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [115950/128000 (91%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [116100/128000 (91%)]\tLoss: 0.000565\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [116250/128000 (91%)]\tLoss: 0.000557\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [116400/128000 (91%)]\tLoss: 0.000557\n",
      "BCE tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [116550/128000 (91%)]\tLoss: 0.000578\n",
      "BCE tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [116700/128000 (91%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [116850/128000 (91%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117000/128000 (91%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117150/128000 (91%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117300/128000 (92%)]\tLoss: 0.000535\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117450/128000 (92%)]\tLoss: 0.000528\n",
      "BCE tensor(0.0719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117600/128000 (92%)]\tLoss: 0.000484\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117750/128000 (92%)]\tLoss: 0.000517\n",
      "BCE tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [117900/128000 (92%)]\tLoss: 0.000532\n",
      "BCE tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118050/128000 (92%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118200/128000 (92%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118350/128000 (92%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0857, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118500/128000 (93%)]\tLoss: 0.000577\n",
      "BCE tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118650/128000 (93%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118800/128000 (93%)]\tLoss: 0.000521\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [118950/128000 (93%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [119100/128000 (93%)]\tLoss: 0.000518\n",
      "BCE tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [119250/128000 (93%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [119400/128000 (93%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [119550/128000 (93%)]\tLoss: 0.000506\n",
      "BCE tensor(0.0797, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [119700/128000 (93%)]\tLoss: 0.000537\n",
      "BCE tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [119850/128000 (94%)]\tLoss: 0.000572\n",
      "BCE tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [120000/128000 (94%)]\tLoss: 0.000514\n",
      "BCE tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [120150/128000 (94%)]\tLoss: 0.000504\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [120300/128000 (94%)]\tLoss: 0.000529\n",
      "BCE tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [120450/128000 (94%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [120600/128000 (94%)]\tLoss: 0.000564\n",
      "BCE tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [120750/128000 (94%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [120900/128000 (94%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121050/128000 (94%)]\tLoss: 0.000582\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121200/128000 (95%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121350/128000 (95%)]\tLoss: 0.000563\n",
      "BCE tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121500/128000 (95%)]\tLoss: 0.000490\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121650/128000 (95%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121800/128000 (95%)]\tLoss: 0.000529\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [121950/128000 (95%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [122100/128000 (95%)]\tLoss: 0.000531\n",
      "BCE tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [122250/128000 (95%)]\tLoss: 0.000502\n",
      "BCE tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [122400/128000 (96%)]\tLoss: 0.000546\n",
      "BCE tensor(0.0757, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [122550/128000 (96%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [122700/128000 (96%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [122850/128000 (96%)]\tLoss: 0.000558\n",
      "BCE tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123000/128000 (96%)]\tLoss: 0.000505\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123150/128000 (96%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123300/128000 (96%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123450/128000 (96%)]\tLoss: 0.000543\n",
      "BCE tensor(0.0722, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123600/128000 (96%)]\tLoss: 0.000498\n",
      "BCE tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123750/128000 (97%)]\tLoss: 0.000548\n",
      "BCE tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [123900/128000 (97%)]\tLoss: 0.000560\n",
      "BCE tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124050/128000 (97%)]\tLoss: 0.000503\n",
      "BCE tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124200/128000 (97%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124350/128000 (97%)]\tLoss: 0.000568\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124500/128000 (97%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124650/128000 (97%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0748, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124800/128000 (97%)]\tLoss: 0.000525\n",
      "BCE tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [124950/128000 (98%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0745, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [125100/128000 (98%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [125250/128000 (98%)]\tLoss: 0.000510\n",
      "BCE tensor(0.0740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [125400/128000 (98%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [125550/128000 (98%)]\tLoss: 0.000534\n",
      "BCE tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [125700/128000 (98%)]\tLoss: 0.000507\n",
      "BCE tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [125850/128000 (98%)]\tLoss: 0.000547\n",
      "BCE tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126000/128000 (98%)]\tLoss: 0.000524\n",
      "BCE tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126150/128000 (98%)]\tLoss: 0.000576\n",
      "BCE tensor(0.0710, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126300/128000 (99%)]\tLoss: 0.000496\n",
      "BCE tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126450/128000 (99%)]\tLoss: 0.000540\n",
      "BCE tensor(0.0690, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126600/128000 (99%)]\tLoss: 0.000496\n",
      "BCE tensor(0.0731, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126750/128000 (99%)]\tLoss: 0.000522\n",
      "BCE tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [126900/128000 (99%)]\tLoss: 0.000545\n",
      "BCE tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [127050/128000 (99%)]\tLoss: 0.000496\n",
      "BCE tensor(0.0712, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [127200/128000 (99%)]\tLoss: 0.000508\n",
      "BCE tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [127350/128000 (99%)]\tLoss: 0.000526\n",
      "BCE tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [127500/128000 (100%)]\tLoss: 0.000561\n",
      "BCE tensor(0.0694, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [127650/128000 (100%)]\tLoss: 0.000485\n",
      "BCE tensor(0.0747, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [127800/128000 (100%)]\tLoss: 0.000527\n",
      "BCE tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.1113, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [42650/128000 (100%)]\tLoss: 0.001545\n",
      "====> Epoch: 1 Average loss: 0.0005\n",
      "BCE tensor(0.0719, device='cuda:0')\n",
      "KLD tensor(0.5303, device='cuda:0')\n",
      "BCE tensor(0.0732, device='cuda:0')\n",
      "KLD tensor(0.5526, device='cuda:0')\n",
      "BCE tensor(0.0750, device='cuda:0')\n",
      "KLD tensor(0.6311, device='cuda:0')\n",
      "BCE tensor(0.0745, device='cuda:0')\n",
      "KLD tensor(0.7787, device='cuda:0')\n",
      "BCE tensor(0.0701, device='cuda:0')\n",
      "KLD tensor(0.5725, device='cuda:0')\n",
      "BCE tensor(0.0753, device='cuda:0')\n",
      "KLD tensor(0.6085, device='cuda:0')\n",
      "BCE tensor(0.0771, device='cuda:0')\n",
      "KLD tensor(0.7773, device='cuda:0')\n",
      "BCE tensor(0.0714, device='cuda:0')\n",
      "KLD tensor(0.5668, device='cuda:0')\n",
      "BCE tensor(0.0784, device='cuda:0')\n",
      "KLD tensor(0.6356, device='cuda:0')\n",
      "BCE tensor(0.0712, device='cuda:0')\n",
      "KLD tensor(0.6100, device='cuda:0')\n",
      "BCE tensor(0.0737, device='cuda:0')\n",
      "KLD tensor(0.5283, device='cuda:0')\n",
      "BCE tensor(0.0774, device='cuda:0')\n",
      "KLD tensor(0.7003, device='cuda:0')\n",
      "BCE tensor(0.0756, device='cuda:0')\n",
      "KLD tensor(0.5365, device='cuda:0')\n",
      "BCE tensor(0.0706, device='cuda:0')\n",
      "KLD tensor(0.5933, device='cuda:0')\n",
      "BCE tensor(0.0713, device='cuda:0')\n",
      "KLD tensor(0.5110, device='cuda:0')\n",
      "BCE tensor(0.0760, device='cuda:0')\n",
      "KLD tensor(0.6843, device='cuda:0')\n",
      "BCE tensor(0.0734, device='cuda:0')\n",
      "KLD tensor(0.7832, device='cuda:0')\n",
      "BCE tensor(0.0747, device='cuda:0')\n",
      "KLD tensor(0.6205, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.6252, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.5828, device='cuda:0')\n",
      "BCE tensor(0.0766, device='cuda:0')\n",
      "KLD tensor(0.7043, device='cuda:0')\n",
      "BCE tensor(0.0691, device='cuda:0')\n",
      "KLD tensor(0.5856, device='cuda:0')\n",
      "BCE tensor(0.0767, device='cuda:0')\n",
      "KLD tensor(0.7058, device='cuda:0')\n",
      "BCE tensor(0.0708, device='cuda:0')\n",
      "KLD tensor(0.5803, device='cuda:0')\n",
      "BCE tensor(0.0717, device='cuda:0')\n",
      "KLD tensor(0.6944, device='cuda:0')\n",
      "BCE tensor(0.0731, device='cuda:0')\n",
      "KLD tensor(0.5539, device='cuda:0')\n",
      "BCE tensor(0.0704, device='cuda:0')\n",
      "KLD tensor(0.5942, device='cuda:0')\n",
      "BCE tensor(0.0755, device='cuda:0')\n",
      "KLD tensor(0.6796, device='cuda:0')\n",
      "BCE tensor(0.0705, device='cuda:0')\n",
      "KLD tensor(0.6490, device='cuda:0')\n",
      "BCE tensor(0.0717, device='cuda:0')\n",
      "KLD tensor(0.7459, device='cuda:0')\n",
      "BCE tensor(0.0714, device='cuda:0')\n",
      "KLD tensor(0.5577, device='cuda:0')\n",
      "BCE tensor(0.0724, device='cuda:0')\n",
      "KLD tensor(0.6783, device='cuda:0')\n",
      "BCE tensor(0.0743, device='cuda:0')\n",
      "KLD tensor(0.6815, device='cuda:0')\n",
      "BCE tensor(0.0759, device='cuda:0')\n",
      "KLD tensor(0.6468, device='cuda:0')\n",
      "BCE tensor(0.0720, device='cuda:0')\n",
      "KLD tensor(0.6191, device='cuda:0')\n",
      "BCE tensor(0.0710, device='cuda:0')\n",
      "KLD tensor(0.6313, device='cuda:0')\n",
      "BCE tensor(0.0739, device='cuda:0')\n",
      "KLD tensor(0.6387, device='cuda:0')\n",
      "BCE tensor(0.0731, device='cuda:0')\n",
      "KLD tensor(0.5888, device='cuda:0')\n",
      "BCE tensor(0.0690, device='cuda:0')\n",
      "KLD tensor(0.6444, device='cuda:0')\n",
      "BCE tensor(0.0746, device='cuda:0')\n",
      "KLD tensor(0.6609, device='cuda:0')\n",
      "BCE tensor(0.0687, device='cuda:0')\n",
      "KLD tensor(0.6127, device='cuda:0')\n",
      "BCE tensor(0.0736, device='cuda:0')\n",
      "KLD tensor(0.5669, device='cuda:0')\n",
      "BCE tensor(0.0742, device='cuda:0')\n",
      "KLD tensor(0.6484, device='cuda:0')\n",
      "BCE tensor(0.0747, device='cuda:0')\n",
      "KLD tensor(0.4281, device='cuda:0')\n",
      "BCE tensor(0.0807, device='cuda:0')\n",
      "KLD tensor(0.6851, device='cuda:0')\n",
      "BCE tensor(0.0750, device='cuda:0')\n",
      "KLD tensor(0.4671, device='cuda:0')\n",
      "BCE tensor(0.0704, device='cuda:0')\n",
      "KLD tensor(0.5804, device='cuda:0')\n",
      "BCE tensor(0.0753, device='cuda:0')\n",
      "KLD tensor(0.6871, device='cuda:0')\n",
      "BCE tensor(0.0678, device='cuda:0')\n",
      "KLD tensor(0.6330, device='cuda:0')\n",
      "BCE tensor(0.0759, device='cuda:0')\n",
      "KLD tensor(0.5282, device='cuda:0')\n",
      "BCE tensor(0.0741, device='cuda:0')\n",
      "KLD tensor(0.6432, device='cuda:0')\n",
      "BCE tensor(0.0729, device='cuda:0')\n",
      "KLD tensor(0.5270, device='cuda:0')\n",
      "BCE tensor(0.0729, device='cuda:0')\n",
      "KLD tensor(0.5988, device='cuda:0')\n",
      "BCE tensor(0.0758, device='cuda:0')\n",
      "KLD tensor(0.6653, device='cuda:0')\n",
      "BCE tensor(0.0708, device='cuda:0')\n",
      "KLD tensor(0.5159, device='cuda:0')\n",
      "BCE tensor(0.0758, device='cuda:0')\n",
      "KLD tensor(0.6042, device='cuda:0')\n",
      "BCE tensor(0.0744, device='cuda:0')\n",
      "KLD tensor(0.6683, device='cuda:0')\n",
      "BCE tensor(0.0716, device='cuda:0')\n",
      "KLD tensor(0.6953, device='cuda:0')\n",
      "BCE tensor(0.0748, device='cuda:0')\n",
      "KLD tensor(0.5295, device='cuda:0')\n",
      "BCE tensor(0.0772, device='cuda:0')\n",
      "KLD tensor(0.5749, device='cuda:0')\n",
      "BCE tensor(0.0695, device='cuda:0')\n",
      "KLD tensor(0.5395, device='cuda:0')\n",
      "BCE tensor(0.0802, device='cuda:0')\n",
      "KLD tensor(1.0468, device='cuda:0')\n",
      "BCE tensor(0.0709, device='cuda:0')\n",
      "KLD tensor(0.5250, device='cuda:0')\n",
      "BCE tensor(0.0702, device='cuda:0')\n",
      "KLD tensor(0.5278, device='cuda:0')\n",
      "BCE tensor(0.0736, device='cuda:0')\n",
      "KLD tensor(0.5072, device='cuda:0')\n",
      "BCE tensor(0.0786, device='cuda:0')\n",
      "KLD tensor(0.7015, device='cuda:0')\n",
      "BCE tensor(0.0725, device='cuda:0')\n",
      "KLD tensor(0.6214, device='cuda:0')\n",
      "BCE tensor(0.0748, device='cuda:0')\n",
      "KLD tensor(0.7422, device='cuda:0')\n",
      "BCE tensor(0.0715, device='cuda:0')\n",
      "KLD tensor(0.4924, device='cuda:0')\n",
      "BCE tensor(0.0741, device='cuda:0')\n",
      "KLD tensor(0.6394, device='cuda:0')\n",
      "BCE tensor(0.0741, device='cuda:0')\n",
      "KLD tensor(0.4893, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.6228, device='cuda:0')\n",
      "BCE tensor(0.0724, device='cuda:0')\n",
      "KLD tensor(0.4795, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.7023, device='cuda:0')\n",
      "BCE tensor(0.0759, device='cuda:0')\n",
      "KLD tensor(0.8063, device='cuda:0')\n",
      "BCE tensor(0.0737, device='cuda:0')\n",
      "KLD tensor(0.6208, device='cuda:0')\n",
      "BCE tensor(0.0720, device='cuda:0')\n",
      "KLD tensor(0.6687, device='cuda:0')\n",
      "BCE tensor(0.0727, device='cuda:0')\n",
      "KLD tensor(0.6210, device='cuda:0')\n",
      "BCE tensor(0.0721, device='cuda:0')\n",
      "KLD tensor(0.5616, device='cuda:0')\n",
      "BCE tensor(0.0694, device='cuda:0')\n",
      "KLD tensor(0.4962, device='cuda:0')\n",
      "BCE tensor(0.0756, device='cuda:0')\n",
      "KLD tensor(0.5819, device='cuda:0')\n",
      "BCE tensor(0.0729, device='cuda:0')\n",
      "KLD tensor(0.5816, device='cuda:0')\n",
      "BCE tensor(0.0702, device='cuda:0')\n",
      "KLD tensor(0.5486, device='cuda:0')\n",
      "BCE tensor(0.0748, device='cuda:0')\n",
      "KLD tensor(0.6120, device='cuda:0')\n",
      "BCE tensor(0.0731, device='cuda:0')\n",
      "KLD tensor(0.6441, device='cuda:0')\n",
      "BCE tensor(0.0764, device='cuda:0')\n",
      "KLD tensor(0.5990, device='cuda:0')\n",
      "BCE tensor(0.0714, device='cuda:0')\n",
      "KLD tensor(0.5296, device='cuda:0')\n",
      "BCE tensor(0.0764, device='cuda:0')\n",
      "KLD tensor(0.6582, device='cuda:0')\n",
      "BCE tensor(0.0703, device='cuda:0')\n",
      "KLD tensor(0.5923, device='cuda:0')\n",
      "BCE tensor(0.0770, device='cuda:0')\n",
      "KLD tensor(0.5401, device='cuda:0')\n",
      "BCE tensor(0.0792, device='cuda:0')\n",
      "KLD tensor(0.6175, device='cuda:0')\n",
      "BCE tensor(0.0714, device='cuda:0')\n",
      "KLD tensor(0.5276, device='cuda:0')\n",
      "BCE tensor(0.0785, device='cuda:0')\n",
      "KLD tensor(0.6131, device='cuda:0')\n",
      "BCE tensor(0.0771, device='cuda:0')\n",
      "KLD tensor(0.6853, device='cuda:0')\n",
      "BCE tensor(0.0763, device='cuda:0')\n",
      "KLD tensor(0.7019, device='cuda:0')\n",
      "BCE tensor(0.0790, device='cuda:0')\n",
      "KLD tensor(0.6109, device='cuda:0')\n",
      "BCE tensor(0.0753, device='cuda:0')\n",
      "KLD tensor(0.6883, device='cuda:0')\n",
      "BCE tensor(0.0727, device='cuda:0')\n",
      "KLD tensor(0.5849, device='cuda:0')\n",
      "BCE tensor(0.0699, device='cuda:0')\n",
      "KLD tensor(0.6472, device='cuda:0')\n",
      "BCE tensor(0.0815, device='cuda:0')\n",
      "KLD tensor(0.6528, device='cuda:0')\n",
      "BCE tensor(0.0717, device='cuda:0')\n",
      "KLD tensor(0.6002, device='cuda:0')\n",
      "BCE tensor(0.0684, device='cuda:0')\n",
      "KLD tensor(0.5389, device='cuda:0')\n",
      "BCE tensor(0.0724, device='cuda:0')\n",
      "KLD tensor(0.5964, device='cuda:0')\n",
      "BCE tensor(0.0763, device='cuda:0')\n",
      "KLD tensor(0.6429, device='cuda:0')\n",
      "BCE tensor(0.0686, device='cuda:0')\n",
      "KLD tensor(0.6330, device='cuda:0')\n",
      "BCE tensor(0.0754, device='cuda:0')\n",
      "KLD tensor(0.7072, device='cuda:0')\n",
      "BCE tensor(0.0760, device='cuda:0')\n",
      "KLD tensor(0.6800, device='cuda:0')\n",
      "BCE tensor(0.0737, device='cuda:0')\n",
      "KLD tensor(0.5900, device='cuda:0')\n",
      "BCE tensor(0.0744, device='cuda:0')\n",
      "KLD tensor(0.5464, device='cuda:0')\n",
      "BCE tensor(0.0703, device='cuda:0')\n",
      "KLD tensor(0.5803, device='cuda:0')\n",
      "BCE tensor(0.0671, device='cuda:0')\n",
      "KLD tensor(0.5681, device='cuda:0')\n",
      "BCE tensor(0.0747, device='cuda:0')\n",
      "KLD tensor(0.6810, device='cuda:0')\n",
      "BCE tensor(0.0728, device='cuda:0')\n",
      "KLD tensor(0.6249, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE tensor(0.0692, device='cuda:0')\n",
      "KLD tensor(0.5555, device='cuda:0')\n",
      "BCE tensor(0.0715, device='cuda:0')\n",
      "KLD tensor(0.5380, device='cuda:0')\n",
      "BCE tensor(0.0782, device='cuda:0')\n",
      "KLD tensor(0.5655, device='cuda:0')\n",
      "BCE tensor(0.0703, device='cuda:0')\n",
      "KLD tensor(0.6174, device='cuda:0')\n",
      "BCE tensor(0.0759, device='cuda:0')\n",
      "KLD tensor(0.7151, device='cuda:0')\n",
      "BCE tensor(0.0746, device='cuda:0')\n",
      "KLD tensor(0.5407, device='cuda:0')\n",
      "BCE tensor(0.0746, device='cuda:0')\n",
      "KLD tensor(0.7002, device='cuda:0')\n",
      "BCE tensor(0.0745, device='cuda:0')\n",
      "KLD tensor(0.6648, device='cuda:0')\n",
      "BCE tensor(0.0751, device='cuda:0')\n",
      "KLD tensor(0.6067, device='cuda:0')\n",
      "BCE tensor(0.0743, device='cuda:0')\n",
      "KLD tensor(0.6301, device='cuda:0')\n",
      "BCE tensor(0.0807, device='cuda:0')\n",
      "KLD tensor(0.6699, device='cuda:0')\n",
      "BCE tensor(0.0682, device='cuda:0')\n",
      "KLD tensor(0.5644, device='cuda:0')\n",
      "BCE tensor(0.0774, device='cuda:0')\n",
      "KLD tensor(0.5952, device='cuda:0')\n",
      "BCE tensor(0.0739, device='cuda:0')\n",
      "KLD tensor(0.6677, device='cuda:0')\n",
      "BCE tensor(0.0758, device='cuda:0')\n",
      "KLD tensor(0.6141, device='cuda:0')\n",
      "BCE tensor(0.0809, device='cuda:0')\n",
      "KLD tensor(0.6889, device='cuda:0')\n",
      "BCE tensor(0.0709, device='cuda:0')\n",
      "KLD tensor(0.6055, device='cuda:0')\n",
      "BCE tensor(0.0773, device='cuda:0')\n",
      "KLD tensor(0.8270, device='cuda:0')\n",
      "BCE tensor(0.0783, device='cuda:0')\n",
      "KLD tensor(0.7613, device='cuda:0')\n",
      "BCE tensor(0.0759, device='cuda:0')\n",
      "KLD tensor(0.5487, device='cuda:0')\n",
      "BCE tensor(0.0705, device='cuda:0')\n",
      "KLD tensor(0.7100, device='cuda:0')\n",
      "BCE tensor(0.0694, device='cuda:0')\n",
      "KLD tensor(0.4927, device='cuda:0')\n",
      "BCE tensor(0.0818, device='cuda:0')\n",
      "KLD tensor(0.7185, device='cuda:0')\n",
      "BCE tensor(0.0711, device='cuda:0')\n",
      "KLD tensor(0.6282, device='cuda:0')\n",
      "BCE tensor(0.0742, device='cuda:0')\n",
      "KLD tensor(0.5690, device='cuda:0')\n",
      "BCE tensor(0.0692, device='cuda:0')\n",
      "KLD tensor(0.6122, device='cuda:0')\n",
      "BCE tensor(0.0755, device='cuda:0')\n",
      "KLD tensor(0.4924, device='cuda:0')\n",
      "BCE tensor(0.0705, device='cuda:0')\n",
      "KLD tensor(0.5522, device='cuda:0')\n",
      "BCE tensor(0.0737, device='cuda:0')\n",
      "KLD tensor(0.7950, device='cuda:0')\n",
      "BCE tensor(0.0759, device='cuda:0')\n",
      "KLD tensor(0.7120, device='cuda:0')\n",
      "BCE tensor(0.0729, device='cuda:0')\n",
      "KLD tensor(0.7137, device='cuda:0')\n",
      "BCE tensor(0.0741, device='cuda:0')\n",
      "KLD tensor(0.6228, device='cuda:0')\n",
      "BCE tensor(0.0728, device='cuda:0')\n",
      "KLD tensor(0.5810, device='cuda:0')\n",
      "BCE tensor(0.0729, device='cuda:0')\n",
      "KLD tensor(0.6441, device='cuda:0')\n",
      "BCE tensor(0.0713, device='cuda:0')\n",
      "KLD tensor(0.4662, device='cuda:0')\n",
      "BCE tensor(0.0725, device='cuda:0')\n",
      "KLD tensor(0.6203, device='cuda:0')\n",
      "BCE tensor(0.0650, device='cuda:0')\n",
      "KLD tensor(0.5628, device='cuda:0')\n",
      "BCE tensor(0.0791, device='cuda:0')\n",
      "KLD tensor(0.5875, device='cuda:0')\n",
      "BCE tensor(0.0740, device='cuda:0')\n",
      "KLD tensor(0.5956, device='cuda:0')\n",
      "BCE tensor(0.0753, device='cuda:0')\n",
      "KLD tensor(0.7514, device='cuda:0')\n",
      "BCE tensor(0.0773, device='cuda:0')\n",
      "KLD tensor(0.7436, device='cuda:0')\n",
      "BCE tensor(0.0740, device='cuda:0')\n",
      "KLD tensor(0.6797, device='cuda:0')\n",
      "BCE tensor(0.0741, device='cuda:0')\n",
      "KLD tensor(0.5975, device='cuda:0')\n",
      "BCE tensor(0.0776, device='cuda:0')\n",
      "KLD tensor(0.7163, device='cuda:0')\n",
      "BCE tensor(0.0758, device='cuda:0')\n",
      "KLD tensor(0.6200, device='cuda:0')\n",
      "BCE tensor(0.0804, device='cuda:0')\n",
      "KLD tensor(0.5931, device='cuda:0')\n",
      "BCE tensor(0.0734, device='cuda:0')\n",
      "KLD tensor(0.6257, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.5350, device='cuda:0')\n",
      "BCE tensor(0.0733, device='cuda:0')\n",
      "KLD tensor(0.5245, device='cuda:0')\n",
      "BCE tensor(0.0737, device='cuda:0')\n",
      "KLD tensor(0.6816, device='cuda:0')\n",
      "BCE tensor(0.0673, device='cuda:0')\n",
      "KLD tensor(0.5562, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.5722, device='cuda:0')\n",
      "BCE tensor(0.0722, device='cuda:0')\n",
      "KLD tensor(0.5753, device='cuda:0')\n",
      "BCE tensor(0.0774, device='cuda:0')\n",
      "KLD tensor(0.5896, device='cuda:0')\n",
      "BCE tensor(0.0762, device='cuda:0')\n",
      "KLD tensor(0.5601, device='cuda:0')\n",
      "BCE tensor(0.0749, device='cuda:0')\n",
      "KLD tensor(0.6482, device='cuda:0')\n",
      "BCE tensor(0.0741, device='cuda:0')\n",
      "KLD tensor(0.6439, device='cuda:0')\n",
      "BCE tensor(0.0748, device='cuda:0')\n",
      "KLD tensor(0.4271, device='cuda:0')\n",
      "====> Test set loss: 0.0005\n",
      "BCE tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [0/128000 (0%)]\tLoss: 0.000544\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [150/128000 (0%)]\tLoss: 0.000562\n",
      "BCE tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.5665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [300/128000 (0%)]\tLoss: 0.000489\n",
      "BCE tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.6288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [450/128000 (0%)]\tLoss: 0.000549\n",
      "BCE tensor(0.0722, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [600/128000 (0%)]\tLoss: 0.000512\n",
      "BCE tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [750/128000 (1%)]\tLoss: 0.000550\n",
      "BCE tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [900/128000 (1%)]\tLoss: 0.000516\n",
      "BCE tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [1050/128000 (1%)]\tLoss: 0.000539\n",
      "BCE tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [1200/128000 (1%)]\tLoss: 0.000542\n",
      "BCE tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [1350/128000 (1%)]\tLoss: 0.000536\n",
      "BCE tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [1500/128000 (1%)]\tLoss: 0.000541\n",
      "BCE tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "KLD tensor(0.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [1650/128000 (1%)]\tLoss: 0.000503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 497, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 466, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 451, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/genericpath.py\", line 26, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 497, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/share/apps/python/2.7.12/intel/lib/python2.7/inspect.py\", line 467, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/posixpath.py\", line 366, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/scratch/um367/urwa-env/py2.7.12/lib/python2.7/posixpath.py\", line 344, in normpath\n",
      "    if comp in ('', '.'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2893\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/um367/urwa-env/py2.7.12/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    #test(epoch)\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, 'vaetest2.pth.tar')\n",
    "#     with torch.no_grad():\n",
    "#         sample = torch.randn(64, 20).to(device)\n",
    "#         sample = model.decode(sample).cpu()\n",
    "#         save_image(sample.view(64, 1, 28, 28),\n",
    "#         'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
